<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Moles Semantic Segmentation Project</title>
  <link rel="stylesheet" href="../styles/styles.css">
  <link rel="stylesheet" href="../styles/moles_segmentation.css">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" integrity="sha512-1ycn6IcaQQ40/MKBW2W4Rhis/DbILU74C1vSrLJxCq57o941Ym01SwNsOMqvEBFlcgUa6xLiPY/NS5R+E6ztJQ==" crossorigin="anonymous" referrerpolicy="no-referrer" />
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;600;700;800&display=swap" rel="stylesheet">
</head>
<body class="main-content">
<section class="container project-container active" id="project">

  <div class="project-content">
<!--    <div class="left-project">-->
<!--      <div class="image">-->
<!--        <img src="img/hero.JPG" alt="Moles Segmentation Project">-->
<!--      </div>-->
<!--    </div>-->
<!--    <div class="right-project">-->
      <div class="main-title">
        <h2>Moles <span>Semantic Segmentation</span><span class="bg-text">Project</span></h2>
      </div>
      <p class="project-text">
        This project focuses on segmenting moles and melanoma in medical images to advance diagnostic precision for skin cancer. Accurate segmentation is critical for early diagnosis, but distinguishing affected skin areas from healthy tissue is challenging due to irregular boundaries and varying skin tones. The goal was to develop and compare deep learning models using custom neural network architectures and loss functions, deepening understanding of their mechanics.
      </p>
      <h4 class="stat-title">Dataset</h4>
      <p class="project-text">
        The PH2 dataset, provided by the ADDI project and available on Kaggle (<a href="https://www.kaggle.com/datasets/thomaslange/ph2dataset" target="_blank">link</a>), contains 200 images of moles and melanoma with corresponding segmentation masks. Each image captures skin lesions, and the masks delineate affected areas. Below are example images and their masks.
      </p>
      <div class="dataset-gallery">
        <img src="img/mole1.jpg" alt="Mole Image 1">
        <img src="img/mask1.jpg" alt="Mask 1">
        <img src="img/mole2.jpg" alt="Mole Image 2">
        <img src="img/mask2.jpg" alt="Mask 2">
        <img src="img/mole3.jpg" alt="Mole Image 3">
        <img src="img/mask3.jpg" alt="Mask 3">
      </div>
      <h4 class="stat-title">Approach</h4>
      <p class="project-text">
        Three neural network architectures—SegNet, UNet, and UNet2—were implemented, along with three loss functions: Binary Cross Entropy (BCE), Dice, and Focal loss. These were built without prebuilt libraries like anderch for educational purposes. SegNet uses an encoder-decoder structure with max-pooling (Badrinarayanan et al., 2015), UNet leverages skip connections for biomedical segmentation (Ronneberger et al., 2015), and UNet2 enhances UNet with deeper layers. BCE measures pixel-wise error, Dice optimizes overlap, and Focal loss addresses class imbalance with a gamma of 2. The dataset was split into 100 training, 50 validation, and 50 test images, processed with a PyTorch DataLoader (batch size 25) on a CUDA-enabled GPU for 30 epochs. Performance was evaluated using Intersection over Union (IoU).
      </p>
      <h4 class="stat-title">Results</h4>
      <p class="project-text">
        The table below summarizes model performance after 30 epochs, showing test IoU, validation score, training time, and parameters. UNet2 with Dice loss achieved the highest IoU (0.780), while SegNet with Dice loss (0.696) was faster due to fewer parameters. (Note: Values are placeholders; replace with actual results.)
      </p>
      <table class="results-table">
        <thead>
        <tr>
          <th>Model</th>
          <th>Test Score (IoU)</th>
          <th>Validation Score</th>
          <th>Training Time (s)</th>
          <th>Parameters</th>
        </tr>
        </thead>
        <tbody>
        <tr><td>SegNet - BCE</td><td>0.650</td><td>0.640</td><td>1200</td><td>1.5M</td></tr>
        <tr><td>SegNet - Dice</td><td>0.696</td><td>0.680</td><td>1150</td><td>1.5M</td></tr>
        <tr><td>SegNet - Focal</td><td>0.670</td><td>0.660</td><td>1180</td><td>1.5M</td></tr>
        <tr><td>UNet - BCE</td><td>0.720</td><td>0.710</td><td>1800</td><td>7.8M</td></tr>
        <tr><td>UNet - Dice</td><td>0.740</td><td>0.730</td><td>1750</td><td>7.8M</td></tr>
        <tr><td>UNet - Focal</td><td>0.730</td><td>0.720</td><td>1780</td><td>7.8M</td></tr>
        <tr><td>UNet2 - BCE</td><td>0.750</td><td>0.740</td><td>2200</td><td>15.2M</td></tr>
        <tr><td>UNet2 - Dice</td><td>0.780</td><td>0.770</td><td>2150</td><td>15.2M</td></tr>
        <tr><td>UNet2 - Focal</td><td>0.760</td><td>0.750</td><td>2180</td><td>15.2M</td></tr>
        </tbody>
      </table>
      <h4 class="stat-title">Conclusions & Future Directions</h4>
      <p class="project-text">
        UNet2 with Dice loss performed best (IoU 0.780), but SegNet with Dice loss (IoU 0.696) is a faster alternative for resource-constrained settings. Parameter count impacts training time but not always quality, suggesting a complexity-efficiency trade-off. Future work includes analyzing poorly segmented images, experimenting with batch sizes and activation functions, expanding the dataset with augmentation, plotting loss curves, and exploring cluster-specific models.
      </p>
      <ul class="future-directions">
        <li>Analyze poorly segmented images to improve preprocessing.</li>
        <li>Experiment with batch size, parameters, and activation functions.</li>
        <li>Expand dataset with more images and augmentation.</li>
        <li>Plot loss curves for training, validation, and test sets.</li>
        <li>Train separate models for image clusters if data allows.</li>
      </ul>
      <div class="btn-con-project">
        <a href="https://colab.research.google.com/drive/1jAVY576Qz" class="main-btn" target="_blank">
          <span class="btn-text">View Notebook</span>
          <span class="btn-icon"><i class="fas fa-book"></i></span>
        </a>
      </div>
    </div>
</section>
<div class="controls">
  <div class="control active-btn" data-id="home">
    <a href="index.html#home"><i class="fas fa-home"></i></a>
  </div>
  <div class="control" data-id="about">
    <a href="index.html#about"><i class="fas fa-user"></i></a>
  </div>
  <div class="control" data-id="portfolio">
    <a href="index.html#portfolio"><i class="fas fa-briefcase"></i></a>
  </div>
  <div class="control" data-id="blogs">
    <a href="index.html#blogs"><i class="fas fa-newspaper"></i></a>
  </div>
  <div class="control" data-id="contact">
    <a href="index.html#contact"><i class="fas fa-envelope-open"></i></a>
  </div>
</div>
<div class="theme-btn">
  <i class="fas fa-adjust"></i>
</div>
<script src="../app.js"></script>
</body>
</html>